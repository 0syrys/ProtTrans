{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Benchmark Bert Model using GPU or CPU <h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>1. Load necessry libraries including huggingface transformers<b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertModel\n",
    "import time\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>2. Set the file location of Bert model<b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelPath = '/media/agemagician/Disk2/share_files/summit/uniref100/bert/30_layers/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>3. Load Bert Model<b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertModel.from_pretrained(modelPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>4. Load the model into the GPU if avilabile and switch to inference mode<b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>5. Benchmark Configuration<b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_batch_size = 8\n",
    "max_batch_size = 32\n",
    "inc_batch_size = 8\n",
    "\n",
    "min_sequence_length = 64\n",
    "max_sequence_length = 512\n",
    "inc_sequence_length = 64\n",
    "\n",
    "iterations = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>6. Start Benchmarking<b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************** Benchmarking using TITAN V **************************\n",
      "************************************ Start *************************************\n",
      "Sequence Length:   64 \t Batch Size:    8 \t Ms per protein 0.01\n",
      "Sequence Length:   64 \t Batch Size:   16 \t Ms per protein 0.01\n",
      "Sequence Length:   64 \t Batch Size:   24 \t Ms per protein 0.01\n",
      "Sequence Length:   64 \t Batch Size:   32 \t Ms per protein 0.00\n",
      "************************************* Done *************************************\n",
      "Sequence Length:  128 \t Batch Size:    8 \t Ms per protein 0.01\n",
      "Sequence Length:  128 \t Batch Size:   16 \t Ms per protein 0.01\n",
      "Sequence Length:  128 \t Batch Size:   24 \t Ms per protein 0.01\n",
      "Sequence Length:  128 \t Batch Size:   32 \t Ms per protein 0.01\n",
      "************************************* Done *************************************\n",
      "Sequence Length:  192 \t Batch Size:    8 \t Ms per protein 0.02\n",
      "Sequence Length:  192 \t Batch Size:   16 \t Ms per protein 0.02\n",
      "Sequence Length:  192 \t Batch Size:   24 \t Ms per protein 0.02\n",
      "Sequence Length:  192 \t Batch Size:   32 \t Ms per protein 0.01\n",
      "************************************* Done *************************************\n",
      "Sequence Length:  256 \t Batch Size:    8 \t Ms per protein 0.02\n",
      "Sequence Length:  256 \t Batch Size:   16 \t Ms per protein 0.02\n",
      "Sequence Length:  256 \t Batch Size:   24 \t Ms per protein 0.02\n",
      "Sequence Length:  256 \t Batch Size:   32 \t Ms per protein 0.02\n",
      "************************************* Done *************************************\n",
      "Sequence Length:  320 \t Batch Size:    8 \t Ms per protein 0.03\n",
      "Sequence Length:  320 \t Batch Size:   16 \t Ms per protein 0.03\n",
      "Sequence Length:  320 \t Batch Size:   24 \t Ms per protein 0.03\n",
      "Sequence Length:  320 \t Batch Size:   32 \t Ms per protein 0.03\n",
      "************************************* Done *************************************\n",
      "Sequence Length:  384 \t Batch Size:    8 \t Ms per protein 0.03\n",
      "Sequence Length:  384 \t Batch Size:   16 \t Ms per protein 0.03\n",
      "Sequence Length:  384 \t Batch Size:   24 \t Ms per protein 0.03\n",
      "Sequence Length:  384 \t Batch Size:   32 \t Ms per protein 0.03\n",
      "************************************* Done *************************************\n",
      "Sequence Length:  448 \t Batch Size:    8 \t Ms per protein 0.04\n",
      "Sequence Length:  448 \t Batch Size:   16 \t Ms per protein 0.04\n",
      "Sequence Length:  448 \t Batch Size:   24 \t Ms per protein 0.04\n",
      "Sequence Length:  448 \t Batch Size:   32 \t Ms per protein 0.04\n",
      "************************************* Done *************************************\n",
      "Sequence Length:  512 \t Batch Size:    8 \t Ms per protein 0.05\n",
      "Sequence Length:  512 \t Batch Size:   16 \t Ms per protein 0.05\n",
      "Sequence Length:  512 \t Batch Size:   24 \t Ms per protein 0.05\n",
      "Sequence Length:  512 \t Batch Size:   32 \t Ms per protein 0.05\n",
      "************************************* Done *************************************\n",
      "*********************************** Finished ***********************************\n"
     ]
    }
   ],
   "source": [
    "device_name = torch.cuda.get_device_name(device.index) if device.type == 'cuda' else 'CPU'\n",
    "\n",
    "with torch.no_grad():\n",
    "    print((' Benchmarking using ' + device_name + ' ').center(80, '*'))\n",
    "    print(' Start '.center(80, '*'))\n",
    "    for sequence_length in range(min_sequence_length,max_sequence_length+1,inc_sequence_length):\n",
    "        for batch_size in range(min_batch_size,max_batch_size+1,inc_batch_size):\n",
    "            start = time.time()\n",
    "            for i in range(iterations):\n",
    "                input_ids = torch.randint(1, 20, (batch_size,sequence_length)).cuda()\n",
    "                results = model(input_ids)[0].cpu().numpy()\n",
    "            end = time.time()\n",
    "            ms_per_protein = (end-start)/(iterations*batch_size)\n",
    "            print('Sequence Length: %4d \\t Batch Size: %4d \\t Ms per protein %4.2f' %(sequence_length,batch_size,ms_per_protein))\n",
    "        print(' Done '.center(80, '*'))\n",
    "    print(' Finished '.center(80, '*'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
