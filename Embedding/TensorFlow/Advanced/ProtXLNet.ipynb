{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ProtXLNet-TF.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNFxc2iDfwt7nGmSGYCz5JW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/agemagician/ProtTrans/blob/master/Embedding/TensorFlow/Advanced/ProtXLNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3PubGNU0dZmr"
      },
      "source": [
        "<h3> Extracting protein sequences' features using XLNet pretrained-model <h3>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SAV0QHxfdZmt"
      },
      "source": [
        "<b>1. Load necessry libraries including huggingface transformers<b>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C34oYIVxdeab"
      },
      "source": [
        "!pip install -q transformers sentencepiece"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3NJPeESYdZmw"
      },
      "source": [
        "import tensorflow as tf\n",
        "from transformers import TFXLNetModel, XLNetTokenizer,XLNetConfig\n",
        "import re\n",
        "import numpy as np"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JftgWQNZeGv3"
      },
      "source": [
        "<b>2. Load the vocabulary and XLNet Model</b>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "70TQTgjadZm-"
      },
      "source": [
        "tokenizer = XLNetTokenizer.from_pretrained(\"Rostlab/prot_xlnet\", do_lower_case=False )"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GAwPBDkiLOam"
      },
      "source": [
        "xlnet_men_len = 512"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2GcmM3pGdZnE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04ef497e-7940-40d8-89ee-0c7b2e58202b"
      },
      "source": [
        "model = TFXLNetModel.from_pretrained(\"Rostlab/prot_xlnet\", mem_len=xlnet_men_len, from_pt=True)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFXLNetModel: ['lm_loss.weight', 'lm_loss.bias']\n",
            "- This IS expected if you are initializing TFXLNetModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFXLNetModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the weights of TFXLNetModel were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFXLNetModel for predictions without further training.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZkqAotTcdZnW"
      },
      "source": [
        "<b>3. Create or load sequences and map rarely occured amino acids (U,Z,O,B) to (X)<b>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a0zwKinIdZnX"
      },
      "source": [
        "sequences_Example = [\"A E T C Z A O\",\"S K T Z P\"]"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EkINwL9DdZna"
      },
      "source": [
        "sequences_Example = [re.sub(r\"[UZOB]\", \"X\", sequence) for sequence in sequences_Example]"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "66BZEB3MdZnf"
      },
      "source": [
        "<b>4. Tokenize, encode sequences and load it into the GPU if possibile<b>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xt5uYuu7dZnf"
      },
      "source": [
        "ids = tokenizer.batch_encode_plus(sequences_Example, add_special_tokens=True, padding=True, return_tensors=\"tf\")"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Grl3ieUhdZnj"
      },
      "source": [
        "input_ids = ids['input_ids']\n",
        "attention_mask = ids['attention_mask']"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zylf1HyBdZnl"
      },
      "source": [
        "<b>5. Extracting sequences' features and load it into the CPU if needed<b>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cFZpgE9py1T1"
      },
      "source": [
        "output = model(input_ids,attention_mask=attention_mask,mems=None)\n",
        "embedding = output.last_hidden_state\n",
        "memory = output.mems"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8IsEs35T0T4"
      },
      "source": [
        "embedding = np.asarray(embedding)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Q2AGxlCUrot"
      },
      "source": [
        "attention_mask = np.asarray(attention_mask)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R6oeRZ7xdZns"
      },
      "source": [
        "<b>6. Remove padding ([PAD]) and special tokens that is added by XLNet model<b>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1XXoVSPDdZns"
      },
      "source": [
        "features = [] \n",
        "for seq_num in range(len(embedding)):\n",
        "    seq_len = (attention_mask[seq_num] == 1).sum()\n",
        "    padded_seq_len = len(attention_mask[seq_num])\n",
        "    seq_emd = embedding[seq_num][padded_seq_len-seq_len:padded_seq_len-2]\n",
        "    features.append(seq_emd)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "swOQ_7r9dZnw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e412dbae-8fab-4134-b539-53c3ac95702f"
      },
      "source": [
        "print(features)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[array([[ 0.48745072, -0.77087957,  0.99001706, ..., -0.37356192,\n",
            "        -1.0589752 ,  0.95599777],\n",
            "       [ 0.2132588 , -0.5478905 ,  0.6115487 , ..., -0.05471386,\n",
            "        -0.87878954,  0.2464511 ],\n",
            "       [ 0.37891257, -0.6396583 ,  0.67224425, ..., -0.1489127 ,\n",
            "        -0.67695737,  0.34598166],\n",
            "       ...,\n",
            "       [ 0.09265009, -0.6810126 ,  0.51818657, ..., -0.32756305,\n",
            "        -0.56731194, -0.16441321],\n",
            "       [-0.08533202, -0.74382424,  0.29890722, ..., -0.24376419,\n",
            "        -0.11153169, -0.72609997],\n",
            "       [-0.4822583 , -0.83816975,  0.08214375, ..., -0.251965  ,\n",
            "        -0.03577391, -0.5348946 ]], dtype=float32), array([[ 1.0403051 , -0.95049536,  0.3353436 , ..., -0.23747307,\n",
            "        -0.275508  ,  0.47948724],\n",
            "       [ 0.5085352 , -0.9508469 ,  1.023512  , ..., -0.05893063,\n",
            "        -0.9752811 ,  0.08713093],\n",
            "       [ 0.65626574, -0.75406295,  0.43234748, ...,  0.36707488,\n",
            "        -0.70632553, -0.5553421 ],\n",
            "       [ 0.5903387 ,  0.1415192 ,  0.29578805, ...,  0.20601025,\n",
            "        -0.8735831 ,  0.8067947 ],\n",
            "       [ 0.41400784,  0.6131683 ,  0.0479233 , ...,  0.18511258,\n",
            "        -0.34098336, -0.41199973]], dtype=float32)]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}