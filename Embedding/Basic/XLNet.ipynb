{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.2"
    },
    "colab": {
      "name": "XLNet.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/agemagician/Prot-Transformers/blob/master/Embedding/Basic/XLNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UjIDWEXCJ0b6",
        "colab_type": "text"
      },
      "source": [
        "<h3> Extracting protein sequences' features using ProtXLNet pretrained-model <h3>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BD2-XqmqJ0b7",
        "colab_type": "text"
      },
      "source": [
        "<b>1. Load necessry libraries including huggingface transformers<b>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a3bTean9J-7k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "3ef2a290-66d1-42d9-fcfb-88f39c002cec"
      },
      "source": [
        "!pip install -q transformers\n",
        "!pip install -q gdown"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 675kB 8.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.8MB 23.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.1MB 58.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 890kB 62.1MB/s \n",
            "\u001b[?25h  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aIy-Dk-OJ0b8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from transformers import XLNetModel, XLNetTokenizer, pipeline\n",
        "import re\n",
        "import numpy as np\n",
        "import os\n",
        "import gdown"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-2CIbvDMJ0cC",
        "colab_type": "text"
      },
      "source": [
        "<b>2. Set the url location of ProtXLNet and the vocabulary file<b>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xRoD0cRFJ0cD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "modelUrl = 'https://drive.google.com/uc?export=download&confirm=BTQ_&id=1EbfVSoOGJycJEOKeRD5y5MdobF-wgpew'\n",
        "configUrl = 'https://drive.google.com/uc?export=download&confirm=BTQ_&id=104kJ8GqLIB0XzAqC8s1txV5UtTODWjnH'\n",
        "vocabUrl = 'https://drive.google.com/uc?export=download&confirm=BTQ_&id=1DgkfkHRpDb9rBCmC53rZd5vFk8vZKIaN'"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QIO8X_1TKO2u",
        "colab_type": "text"
      },
      "source": [
        "<b>3. Download Electra models and vocabulary files<b>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0yX5Ixp4Kry6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "downloadFolderPath = 'models/ProtXLNet/'"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tA28vsYCKvPM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "modelFolderPath = downloadFolderPath\n",
        "\n",
        "modelFilePath = os.path.join(modelFolderPath, 'pytorch_model.bin')\n",
        "\n",
        "configFilePath = os.path.join(modelFolderPath, 'config.json')\n",
        "\n",
        "vocabFilePath = os.path.join(modelFolderPath, 'spm_model.model')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A0eqpXy1KvT9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if not os.path.exists(modelFolderPath):\n",
        "    os.makedirs(modelFolderPath)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xGJFY7XdLHOG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def download_file(url,filename):\n",
        "  while not os.path.exists(filename):\n",
        "    gdown.download(url,filename, quiet=False)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0tmFDeemLKyw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "43de7a46-80ce-407c-a63e-3a3b3fa5c454"
      },
      "source": [
        "if not os.path.exists(modelFilePath):\n",
        "    download_file(modelUrl, modelFilePath)\n",
        "\n",
        "if not os.path.exists(configFilePath):\n",
        "    download_file(configUrl, configFilePath)\n",
        "\n",
        "if not os.path.exists(vocabFilePath):\n",
        "    download_file(vocabUrl, vocabFilePath)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?export=download&confirm=BTQ_&id=1EbfVSoOGJycJEOKeRD5y5MdobF-wgpew\n",
            "To: /content/models/ProtXLNet/pytorch_model.bin\n",
            "1.64GB [00:07, 214MB/s] \n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?export=download&confirm=BTQ_&id=104kJ8GqLIB0XzAqC8s1txV5UtTODWjnH\n",
            "To: /content/models/ProtXLNet/config.json\n",
            "100%|██████████| 1.35k/1.35k [00:00<00:00, 1.75MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?export=download&confirm=BTQ_&id=1DgkfkHRpDb9rBCmC53rZd5vFk8vZKIaN\n",
            "To: /content/models/ProtXLNet/spm_model.model\n",
            "100%|██████████| 238k/238k [00:00<00:00, 58.1MB/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B7Op-POnJ0cI",
        "colab_type": "text"
      },
      "source": [
        "<b>4. Load the vocabulary and ProtXLNet Model<b>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NiWe3_MEJ0cJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab = XLNetTokenizer(vocabFilePath, do_lower_case=False)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TIAg52ixJ0cN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = XLNetModel.from_pretrained(modelFolderPath)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3jkCctT1J0cS",
        "colab_type": "text"
      },
      "source": [
        "<b>5. Load the model into the GPU if avilabile<b>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cifZjuMbJ0cS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = pipeline('feature-extraction', model=model, tokenizer=vocab,device=0)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kCAdlY5YJ0cW",
        "colab_type": "text"
      },
      "source": [
        "<b>6. Create or load sequences and map rarely occured amino acids (U,Z,O,B) to (X)<b>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5nYqFMDRJ0cX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sequences_Example = [\"A E T C Z A O\",\"S K T Z P\"]"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5fSzAeM9J0cc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sequences_Example = [re.sub(r\"[UZOB]\", \"X\", sequence) for sequence in sequences_Example]"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zc2cEpE7J0cg",
        "colab_type": "text"
      },
      "source": [
        "<b>6. Extracting sequences' features and covert the output to numpy if needed<b>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rNowPJYgJ0ch",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedding = model(sequences_Example)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v7QLt3qWJ0cl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedding = np.array(embedding)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uocPT992J0cy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        },
        "outputId": "32bcd321-fa69-41a2-9929-ad908b108ce1"
      },
      "source": [
        "print(embedding)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[[ 5.69581509e-01 -8.12228858e-01  1.51267886e+00 ... -3.47372681e-01\n",
            "   -1.97737586e+00  1.02282548e+00]\n",
            "  [ 2.76618991e-02 -6.71196997e-01  9.98873472e-01 ...  7.27679655e-02\n",
            "   -1.62625980e+00 -8.44566710e-03]\n",
            "  [ 2.20987082e-01 -5.26815534e-01  6.64871037e-01 ...  4.78142388e-02\n",
            "   -1.39787078e+00  3.08237135e-01]\n",
            "  ...\n",
            "  [-3.64926189e-01 -8.19321334e-01  4.81532872e-01 ...  2.35715955e-01\n",
            "   -6.73882365e-01 -1.06030309e+00]\n",
            "  [ 4.51356888e-01 -8.96942139e-01  4.00962055e-01 ... -1.93732992e-01\n",
            "   -5.60827136e-01 -2.78552026e-01]\n",
            "  [ 3.18278044e-01 -1.61192930e+00  4.94406074e-01 ... -2.51359522e-01\n",
            "   -1.32739976e-01 -1.23092830e-02]]\n",
            "\n",
            " [[ 1.91231534e-01  1.84455216e-02 -1.82765443e-03 ... -4.36504632e-01\n",
            "    2.18422841e-02 -1.59097195e-01]\n",
            "  [ 2.63838232e-01 -6.02961145e-02 -1.12764817e-02 ... -2.28307739e-01\n",
            "   -3.21160257e-01  1.10596135e-01]\n",
            "  [ 8.65126610e-01 -1.61868662e-01 -1.75777614e-01 ...  3.56551766e-01\n",
            "   -2.34120205e-01  4.93936874e-02]\n",
            "  ...\n",
            "  [ 4.84943122e-01  6.79004431e-01  3.08672816e-01 ...  7.47226924e-02\n",
            "   -3.86943966e-01 -3.16799879e-01]\n",
            "  [ 8.82354438e-01  1.08732784e+00  1.10507198e-01 ...  2.86996424e-01\n",
            "   -1.13194668e+00  7.79393092e-02]\n",
            "  [ 5.38626492e-01 -1.53347459e-02 -6.67607427e-01 ...  6.61960661e-01\n",
            "    1.94272529e-02 -7.00097084e-01]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8wGuhtK3J0c1",
        "colab_type": "text"
      },
      "source": [
        "<b>Optional: Remove padding ([PAD]) and special tokens ([CLS],[SEP]) that is added by ProtXLNet model<b>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ZSpwbj5J0c1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "features = [] \n",
        "for seq_num in range(len(embedding)):\n",
        "    seq_len = len(sequences_Example[seq_num].replace(\" \", \"\"))\n",
        "    padded_seq_len = len(embedding[seq_num])\n",
        "    start_Idx = padded_seq_len-seq_len-2\n",
        "    end_Idx = padded_seq_len-2\n",
        "    seq_emd = embedding[seq_num][start_Idx:end_Idx]\n",
        "    features.append(seq_emd)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hTJ1lTjQJ0c6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "2418bede-8240-4bae-b4ac-38593eba393e"
      },
      "source": [
        "print(features)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[array([[ 0.56958151, -0.81222886,  1.51267886, ..., -0.34737268,\n",
            "        -1.97737586,  1.02282548],\n",
            "       [ 0.0276619 , -0.671197  ,  0.99887347, ...,  0.07276797,\n",
            "        -1.6262598 , -0.00844567],\n",
            "       [ 0.22098708, -0.52681553,  0.66487104, ...,  0.04781424,\n",
            "        -1.39787078,  0.30823714],\n",
            "       ...,\n",
            "       [ 0.70799673, -0.66436064,  0.85833871, ..., -0.02473333,\n",
            "        -1.51670885, -0.21759868],\n",
            "       [-0.14213681, -0.86483932,  0.81442791, ..., -0.32999074,\n",
            "        -0.23385319, -1.7195524 ],\n",
            "       [-0.36492619, -0.81932133,  0.48153287, ...,  0.23571596,\n",
            "        -0.67388237, -1.06030309]]), array([[ 0.86512661, -0.16186866, -0.17577761, ...,  0.35655177,\n",
            "        -0.23412021,  0.04939369],\n",
            "       [ 0.16243157, -0.22352344,  0.53584576, ...,  0.37107557,\n",
            "        -0.72951031, -0.2967481 ],\n",
            "       [ 0.64317816, -0.07562806,  0.37602407, ...,  0.80507094,\n",
            "        -1.03585243, -0.67776829],\n",
            "       [ 0.67437637,  0.27612588,  0.44298318, ...,  0.13377103,\n",
            "        -0.96995842,  0.94658542],\n",
            "       [ 0.48494312,  0.67900443,  0.30867282, ...,  0.07472269,\n",
            "        -0.38694397, -0.31679988]])]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}