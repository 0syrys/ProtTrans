{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Extracting protein sequences' features using Bert pretrained-model <h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>1. Load necessry libraries including huggingface transformers<b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0511 17:18:20.563724 140401596041024 file_utils.py:38] PyTorch version 1.2.0 available.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertModel, BertTokenizer\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>2. Set the file location of Bert and the vocabulary file<b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelPath = '/media/agemagician/Disk2/share_files/summit/uniref100/bert/30_layers/'\n",
    "vocabPath = '/media/agemagician/Disk2/share_files/summit/uniref100/bert/30_layers/vocab.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>3. Load the vocabulary and Bert Model<b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = BertTokenizer(vocabPath, do_lower_case=False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0511 17:18:22.531367 140401596041024 configuration_utils.py:283] loading configuration file /media/agemagician/Disk2/share_files/summit/uniref100/bert/30_layers/config.json\n",
      "I0511 17:18:22.532532 140401596041024 configuration_utils.py:321] Model config BertConfig {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 30,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30\n",
      "}\n",
      "\n",
      "I0511 17:18:22.533591 140401596041024 modeling_utils.py:613] loading weights file /media/agemagician/Disk2/share_files/summit/uniref100/bert/30_layers/pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "model = BertModel.from_pretrained(modelPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>4. Load the model into the GPU if avilabile and switch to inference mode<b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>5. Create or load sequences and map rarely occured amino acids (U,Z,O,B) to (X)<b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences_Example = [\"A E T C U Z A O\",\"S K T Z P\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences_Example = [re.sub(r\"[UZOB]\", \"X\", sequence) for sequence in sequences_Example]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>6. Tokenize, encode sequences and load it into the GPU if possibile<b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = vocab.batch_encode_plus(sequences_Example, add_special_tokens=True, pad_to_max_length=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = torch.tensor(ids['input_ids']).to(device)\n",
    "attention_mask = torch.tensor(ids['attention_mask']).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>7. Extracting sequences' features and load it into the CPU if needed<b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    embedding = model(input_ids=input_ids,attention_mask=attention_mask)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = embedding.cpu().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>8. Remove padding ([PAD]) and special tokens ([CLS],[SEP]) that is added by Bert model<b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [] \n",
    "for seq_num in range(len(embedding)):\n",
    "    seq_len = (attention_mask[seq_num] == 1).sum()\n",
    "    seq_emd = embedding[seq_num][1:seq_len-1]\n",
    "    features.append(seq_emd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[ 0.2938253 , -0.31482786,  0.40421957, ..., -0.8142678 ,\n",
      "        -0.4318575 , -0.7061204 ],\n",
      "       [ 0.29858002, -0.40214115,  0.0622488 , ..., -0.5973166 ,\n",
      "        -0.46130005, -0.5108361 ],\n",
      "       [ 0.21371712, -0.8562609 , -0.02715043, ..., -0.9634674 ,\n",
      "        -0.39202294, -0.8561534 ],\n",
      "       ...,\n",
      "       [ 0.26898074, -0.43959922,  0.18519157, ..., -0.59704864,\n",
      "        -0.5959007 , -0.9337962 ],\n",
      "       [ 0.11302336, -0.1585626 , -0.16294032, ..., -0.6859587 ,\n",
      "        -0.34893864, -0.6644583 ],\n",
      "       [ 0.23447797, -0.46939224,  0.06499285, ..., -0.7182949 ,\n",
      "        -0.56220186, -0.93735063]], dtype=float32), array([[ 0.37563682, -0.5043733 ,  0.23671712, ..., -0.5000316 ,\n",
      "        -0.5415094 , -0.60804015],\n",
      "       [ 0.312288  , -0.58586055,  0.18060336, ..., -0.56324434,\n",
      "        -0.24149302, -0.47199208],\n",
      "       [ 0.014244  , -0.09987319,  0.26524097, ..., -0.5579204 ,\n",
      "        -0.33171567, -0.4138374 ],\n",
      "       [ 0.46875668, -0.51341325,  0.05718547, ..., -0.28536555,\n",
      "        -0.73902327, -0.8001848 ],\n",
      "       [ 0.27606362, -0.56889296,  0.23160987, ..., -0.11474267,\n",
      "        -0.57887495, -0.48494473]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "print(features)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
