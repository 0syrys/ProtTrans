{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Extracting protein sequences' features using Electra pretrained-model <h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>1. Load necessry libraries including huggingface transformers<b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import ElectraTokenizer, ElectraForPreTraining, ElectraForMaskedLM, ElectraModel\n",
    "import re\n",
    "import urllib\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>2. Set the url location of Electra and the vocabulary file<b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "generatorModelUrl = 'ftp://rostlab.org/bio-transformers/models/electra/pytorch/uniref100/generator/pytorch_model.bin'\n",
    "discriminatorModelUrl = 'ftp://rostlab.org/bio-transformers/models/electra/pytorch/uniref100/discriminator/pytorch_model.bin'\n",
    "\n",
    "generatorConfigUrl = 'ftp://rostlab.org/bio-transformers/models/electra/pytorch/uniref100/generator/config.json'\n",
    "discriminatorConfigUrl = 'ftp://rostlab.org/bio-transformers/models/electra/pytorch/uniref100/discriminator/config.json'\n",
    "\n",
    "vocabUrl = 'ftp://rostlab.org/bio-transformers/models/electra/pytorch/uniref100/discriminator/vocab.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>3. Download Electra models and vocabulary files<b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "downloadFolderPath = 'tmp/electra/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminatorFolderPath = os.path.join(downloadFolderPath, 'discriminator')\n",
    "generatorFolderPath = os.path.join(downloadFolderPath, 'generator')\n",
    "\n",
    "discriminatorModelFilePath = os.path.join(discriminatorFolderPath, 'pytorch_model.bin')\n",
    "generatorModelFilePath = os.path.join(generatorFolderPath, 'pytorch_model.bin')\n",
    "\n",
    "discriminatorConfigFilePath = os.path.join(discriminatorFolderPath, 'config.json')\n",
    "generatorConfigFilePath = os.path.join(generatorFolderPath, 'config.json')\n",
    "\n",
    "vocabFilePath = os.path.join(downloadFolderPath, 'vocab.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(discriminatorFolderPath):\n",
    "    os.makedirs(discriminatorFolderPath)\n",
    "if not os.path.exists(generatorFolderPath):\n",
    "    os.makedirs(generatorFolderPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(generatorModelFilePath):\n",
    "    urllib.request.urlretrieve(generatorModelUrl, generatorModelFilePath)\n",
    "\n",
    "if not os.path.exists(discriminatorModelFilePath):\n",
    "    urllib.request.urlretrieve(discriminatorModelUrl, discriminatorModelFilePath)\n",
    "    \n",
    "if not os.path.exists(generatorConfigFilePath):\n",
    "    urllib.request.urlretrieve(generatorConfigUrl, generatorConfigFilePath)\n",
    "\n",
    "if not os.path.exists(discriminatorConfigFilePath):\n",
    "    urllib.request.urlretrieve(discriminatorConfigUrl, discriminatorConfigFilePath)\n",
    "    \n",
    "if not os.path.exists(vocabFilePath):\n",
    "    urllib.request.urlretrieve(vocabUrl, vocabFilePath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>4. Load the vocabulary and Electra discriminator and generator Models<b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = ElectraTokenizer(vocabFilePath, do_lower_case=False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = ElectraForPreTraining.from_pretrained(discriminatorFolderPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = ElectraForMaskedLM.from_pretrained(generatorFolderPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "electra = ElectraModel.from_pretrained(discriminatorFolderPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>5. Load the model into the GPU if avilabile and switch to inference mode<b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = discriminator.to(device)\n",
    "discriminator = discriminator.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = generator.to(device)\n",
    "generator = generator.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "electra = electra.to(device)\n",
    "electra = electra.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>6. Create or load sequences and map rarely occured amino acids (U,Z,O,B) to (X)<b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences_Example = [\"A E T C Z A O\",\"S K T Z P\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences_Example = [re.sub(r\"[UZOB]\", \"X\", sequence) for sequence in sequences_Example]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>7. Tokenize, encode sequences and load it into the GPU if possibile<b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = vocab.batch_encode_plus(sequences_Example, add_special_tokens=True, pad_to_max_length=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = torch.tensor(ids['input_ids']).to(device)\n",
    "attention_mask = torch.tensor(ids['attention_mask']).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>8. Extracting sequences' features and load it into the CPU if needed<b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    discriminator_embedding = discriminator(input_ids=input_ids,attention_mask=attention_mask)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator_embedding = discriminator_embedding.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    generator_embedding = generator(input_ids=input_ids,attention_mask=attention_mask)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_embedding = generator_embedding.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    electra_embedding = electra(input_ids=input_ids,attention_mask=attention_mask)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "electra_embedding = electra_embedding.cpu().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>9. Remove padding ([PAD]) and special tokens ([CLS],[SEP]) that is added by Electra model<b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [] \n",
    "for seq_num in range(len(electra_embedding)):\n",
    "    seq_len = (attention_mask[seq_num] == 1).sum()\n",
    "    seq_emd = electra_embedding[seq_num][1:seq_len-1]\n",
    "    features.append(seq_emd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[-3.11757270e-02, -1.18080482e-01, -1.51422888e-01, ...,\n",
      "        -8.80779102e-02, -2.03648835e-01,  2.34548226e-02],\n",
      "       [-6.92144260e-02, -7.63375461e-02, -1.78090129e-02, ...,\n",
      "        -4.15136591e-02, -3.08615640e-02, -8.58286917e-02],\n",
      "       [ 3.80903780e-02, -1.71692193e-01, -5.64221852e-02, ...,\n",
      "        -1.18379034e-01, -9.77955908e-02,  2.44729687e-02],\n",
      "       ...,\n",
      "       [ 1.27262741e-01, -1.34989783e-01, -3.06518853e-01, ...,\n",
      "         3.99144813e-02, -4.54520248e-02, -3.57909858e-01],\n",
      "       [-5.05250208e-02, -9.02514383e-02,  6.78477511e-02, ...,\n",
      "        -4.76735011e-02, -9.57429931e-02, -1.68221872e-02],\n",
      "       [ 3.07772551e-02,  7.55244400e-05, -5.32223955e-02, ...,\n",
      "        -1.47998398e-02, -1.57045141e-01, -9.64659974e-02]], dtype=float32), array([[-6.04736097e-02, -1.60798252e-01, -1.63700730e-01, ...,\n",
      "        -7.67329112e-02, -1.51252106e-01, -4.52130586e-02],\n",
      "       [-9.30741653e-02, -5.02011962e-02, -1.62956715e-02, ...,\n",
      "        -2.65419309e-04, -2.70892959e-03, -2.37736460e-02],\n",
      "       [-4.23042327e-02, -1.51860461e-01, -6.50826469e-02, ...,\n",
      "        -1.45552168e-02, -7.37643838e-02, -5.66907823e-02],\n",
      "       [ 4.75768261e-02, -7.08767474e-02, -2.75032043e-01, ...,\n",
      "        -1.02747336e-01, -1.06809035e-01, -2.18676105e-01],\n",
      "       [-4.99714017e-02,  1.03256376e-02, -9.70155671e-02, ...,\n",
      "        -1.18602112e-01,  7.05885421e-03, -1.71629369e-01]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
