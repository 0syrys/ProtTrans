{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.2"
    },
    "colab": {
      "name": "Bert.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/agemagician/Prot-Transformers/blob/master/Embedding/Advanced/Bert.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3PubGNU0dZmr",
        "colab_type": "text"
      },
      "source": [
        "<h3> Extracting protein sequences' features using ProtBert pretrained-model <h3>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SAV0QHxfdZmt",
        "colab_type": "text"
      },
      "source": [
        "<b>1. Load necessry libraries including huggingface transformers<b>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C34oYIVxdeab",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "c3862741-695a-4bfe-ed2b-a4beee4247e8"
      },
      "source": [
        "!pip install -q transformers\n",
        "!pip install -q git+https://github.com/wkentaro/gdown.git"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for gdown (PEP 517) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3NJPeESYdZmw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from transformers import BertModel, BertTokenizer\n",
        "import re\n",
        "import os\n",
        "import gdown"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hvF6bcUedkux",
        "colab_type": "text"
      },
      "source": [
        "<b>2. Set the url location of ProtBert and the vocabulary file<b>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EwbgypGodpb4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "modelUrl = 'https://drive.google.com/uc?export=download&id=1mLuVhMuGTSSfVkK1rrmBSTC5yiCpGy--'\n",
        "configUrl = 'https://drive.google.com/uc?export=download&id=1hg30JtXz6Okl0esJnMC2J_9TNbx5gJpl'\n",
        "vocabUrl = 'https://drive.google.com/uc?export=download&id=15eFspbhoF5uUZ6xKKTAIGOunXYDeFruL'"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kDsDWsIWdZm9",
        "colab_type": "text"
      },
      "source": [
        "<b>3. Download ProtBert models and vocabulary files<b>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5PYDZA8kdyLb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "downloadFolderPath = 'models/ProtBert/'"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HqhYZVjBdyXU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "modelFolderPath = downloadFolderPath\n",
        "\n",
        "modelFilePath = os.path.join(modelFolderPath, 'pytorch_model.bin')\n",
        "\n",
        "configFilePath = os.path.join(modelFolderPath, 'config.json')\n",
        "\n",
        "vocabFilePath = os.path.join(modelFolderPath, 'vocab.txt')"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n7QYqrPpdyeb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if not os.path.exists(modelFolderPath):\n",
        "    os.makedirs(modelFolderPath)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pcgz8DsedyVz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def download_file(url,filename):\n",
        "  while not os.path.exists(filename):\n",
        "    gdown.download(url,filename, quiet=False)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PvpVdE27dyQ7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "678b71ef-785b-43e8-cc3d-750dbd7450e7"
      },
      "source": [
        "if not os.path.exists(modelFilePath):\n",
        "    download_file(modelUrl, modelFilePath)\n",
        "\n",
        "if not os.path.exists(configFilePath):\n",
        "    download_file(configUrl, configFilePath)\n",
        "\n",
        "if not os.path.exists(vocabFilePath):\n",
        "    download_file(vocabUrl, vocabFilePath)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?export=download&id=1mLuVhMuGTSSfVkK1rrmBSTC5yiCpGy--\n",
            "To: /content/models/ProtBert/pytorch_model.bin\n",
            "1.68GB [00:19, 85.1MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?export=download&id=1hg30JtXz6Okl0esJnMC2J_9TNbx5gJpl\n",
            "To: /content/models/ProtBert/config.json\n",
            "100%|██████████| 313/313 [00:00<00:00, 468kB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?export=download&id=15eFspbhoF5uUZ6xKKTAIGOunXYDeFruL\n",
            "To: /content/models/ProtBert/vocab.txt\n",
            "100%|██████████| 81.0/81.0 [00:00<00:00, 133kB/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JftgWQNZeGv3",
        "colab_type": "text"
      },
      "source": [
        "<b>4. Load the vocabulary and ProtBert Model</b>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "70TQTgjadZm-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = BertTokenizer(vocabFilePath, do_lower_case=False )"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2GcmM3pGdZnE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = BertModel.from_pretrained(modelFolderPath)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eM-12RxodZnK",
        "colab_type": "text"
      },
      "source": [
        "<b>5. Load the model into the GPU if avilabile and switch to inference mode<b>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xxElo34RdZnL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YyQf6mwQdZnP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = model.to(device)\n",
        "model = model.eval()"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZkqAotTcdZnW",
        "colab_type": "text"
      },
      "source": [
        "<b>6. Create or load sequences and map rarely occured amino acids (U,Z,O,B) to (X)<b>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a0zwKinIdZnX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sequences_Example = [\"A E T C Z A O\",\"S K T Z P\"]"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EkINwL9DdZna",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sequences_Example = [re.sub(r\"[UZOB]\", \"X\", sequence) for sequence in sequences_Example]"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "66BZEB3MdZnf",
        "colab_type": "text"
      },
      "source": [
        "<b>7. Tokenize, encode sequences and load it into the GPU if possibile<b>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xt5uYuu7dZnf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ids = tokenizer.batch_encode_plus(sequences_Example, add_special_tokens=True, pad_to_max_length=True)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Grl3ieUhdZnj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_ids = torch.tensor(ids['input_ids']).to(device)\n",
        "attention_mask = torch.tensor(ids['attention_mask']).to(device)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zylf1HyBdZnl",
        "colab_type": "text"
      },
      "source": [
        "<b>8. Extracting sequences' features and load it into the CPU if needed<b>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i8CVGPRFdZnm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with torch.no_grad():\n",
        "    embedding = model(input_ids=input_ids,attention_mask=attention_mask)[0]"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dvgfP2h3dZnq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedding = embedding.cpu().numpy()"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R6oeRZ7xdZns",
        "colab_type": "text"
      },
      "source": [
        "<b>9. Remove padding ([PAD]) and special tokens ([CLS],[SEP]) that is added by Bert model<b>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1XXoVSPDdZns",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "features = [] \n",
        "for seq_num in range(len(embedding)):\n",
        "    seq_len = (attention_mask[seq_num] == 1).sum()\n",
        "    seq_emd = embedding[seq_num][1:seq_len-1]\n",
        "    features.append(seq_emd)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "swOQ_7r9dZnw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "dc58f87a-4229-4e05-d86c-eca36628e6d0"
      },
      "source": [
        "print(features)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[array([[ 0.09233951,  0.13914399, -0.05241546, ..., -0.13947977,\n",
            "        -0.0428006 ,  0.07431364],\n",
            "       [ 0.11505969,  0.01998261, -0.08627468, ..., -0.00946233,\n",
            "        -0.1872724 ,  0.13169006],\n",
            "       [ 0.04012022,  0.05467906, -0.0424584 , ...,  0.02054804,\n",
            "        -0.03819017,  0.1011811 ],\n",
            "       ...,\n",
            "       [ 0.08853199,  0.0228724 , -0.05121122, ..., -0.0673336 ,\n",
            "        -0.03013714,  0.04913732],\n",
            "       [ 0.10792391,  0.09771117, -0.05832333, ..., -0.12765658,\n",
            "        -0.06493297,  0.12894136],\n",
            "       [ 0.0545795 ,  0.03635893, -0.07821195, ..., -0.03016043,\n",
            "        -0.06015311,  0.08903892]], dtype=float32), array([[ 0.0880546 ,  0.10885102,  0.06212992, ...,  0.0144938 ,\n",
            "        -0.03327068, -0.0362049 ],\n",
            "       [-0.03332657,  0.03442192,  0.0809955 , ...,  0.0008738 ,\n",
            "        -0.02733596,  0.05783575],\n",
            "       [ 0.07896441,  0.10343076, -0.01508527, ...,  0.06711898,\n",
            "        -0.01733149,  0.12912118],\n",
            "       [ 0.01805276,  0.07072446, -0.03629201, ..., -0.03547218,\n",
            "         0.0481908 ,  0.0542736 ],\n",
            "       [ 0.05880854,  0.02880943, -0.08032861, ..., -0.00561737,\n",
            "         0.03985041,  0.10529047]], dtype=float32)]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}