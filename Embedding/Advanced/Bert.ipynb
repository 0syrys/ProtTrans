{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Extracting protein sequences' features using Bert pretrained-model <h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>1. Load necessry libraries including huggingface transformers<b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertModel, BertTokenizer\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>2. Set the file location of Bert and the vocabulary file<b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelPath = '/media/agemagician/Disk2/share_files/summit/uniref100/bert/30_layers/'\n",
    "vocabPath = '/media/agemagician/Disk2/share_files/summit/uniref100/bert/30_layers/vocab.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>3. Load the vocabulary and Bert Model<b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = BertTokenizer(vocabPath, do_lower_case=False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertModel.from_pretrained(modelPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>4. Load the model into the GPU if avilabile and switch to inference mode<b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>5. Create or load sequences and map rarely occured amino acids (U,Z,O,B) to (X)<b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences_Example = [\"A E T C Z A O\",\"S K T Z P\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences_Example = [re.sub(r\"[UZOB]\", \"X\", sequence) for sequence in sequences_Example]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>6. Tokenize, encode sequences and load it into the GPU if possibile<b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = vocab.batch_encode_plus(sequences_Example, add_special_tokens=True, pad_to_max_length=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = torch.tensor(ids['input_ids']).to(device)\n",
    "attention_mask = torch.tensor(ids['attention_mask']).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>7. Extracting sequences' features and load it into the CPU if needed<b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    embedding = model(input_ids=input_ids,attention_mask=attention_mask)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = embedding.cpu().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>8. Remove padding ([PAD]) and special tokens ([CLS],[SEP]) that is added by Bert model<b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [] \n",
    "for seq_num in range(len(embedding)):\n",
    "    seq_len = (attention_mask[seq_num] == 1).sum()\n",
    "    seq_emd = embedding[seq_num][1:seq_len-1]\n",
    "    features.append(seq_emd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[ 0.3434632 , -0.11853541,  0.11670393, ...,  0.12733918,\n",
      "        -0.33663505, -0.4125227 ],\n",
      "       [ 0.37897065, -0.2309679 ,  0.00771705, ..., -0.44364253,\n",
      "        -0.56715494, -0.63721484],\n",
      "       [ 0.28404582, -0.5655926 ,  0.06742072, ..., -0.80574137,\n",
      "        -0.64692605, -0.66759783],\n",
      "       ...,\n",
      "       [ 0.38815227, -0.2500954 ,  0.1672174 , ..., -0.53784174,\n",
      "        -0.37415683, -0.5270342 ],\n",
      "       [ 0.69124544, -0.44460136,  0.00450774, ..., -0.3540218 ,\n",
      "        -0.46115145, -0.7682186 ],\n",
      "       [ 0.59799904, -0.23531727,  0.09535453, ..., -0.5865146 ,\n",
      "        -0.61789775, -0.80608463]], dtype=float32), array([[ 0.36907712, -0.5154992 ,  0.2521861 , ..., -0.5068797 ,\n",
      "        -0.5616515 , -0.6157087 ],\n",
      "       [ 0.32650244, -0.5830976 ,  0.19571821, ..., -0.57145095,\n",
      "        -0.25643727, -0.47911468],\n",
      "       [ 0.0239465 , -0.10554147,  0.27909502, ..., -0.5566634 ,\n",
      "        -0.3446969 , -0.42556283],\n",
      "       [ 0.467527  , -0.51940775,  0.0586937 , ..., -0.28577682,\n",
      "        -0.73576313, -0.7956314 ],\n",
      "       [ 0.27339718, -0.6207601 ,  0.2452506 , ..., -0.09948505,\n",
      "        -0.5927241 , -0.5041654 ]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "print(features)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
