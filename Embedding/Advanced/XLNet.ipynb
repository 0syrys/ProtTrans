{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.2"
    },
    "colab": {
      "name": "XLNet.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/agemagician/Prot-Transformers/blob/master/Embedding/Advanced/XLNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WZbZ-X1nNX5y",
        "colab_type": "text"
      },
      "source": [
        "<h3> Extracting protein sequences' features using ProtXLNet pretrained-model <h3>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2dP1skIiNX51",
        "colab_type": "text"
      },
      "source": [
        "<b>1. Load necessry libraries including huggingface transformers<b>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VqLdcEsgNgmu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "9ff3fd6e-27d8-44de-ed09-2da1a0b22b4d"
      },
      "source": [
        "!pip install -q transformers\n",
        "!pip install -q gdown"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 675kB 3.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.1MB 16.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 890kB 24.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.8MB 33.2MB/s \n",
            "\u001b[?25h  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xD5QbnlPNX53",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from transformers import XLNetModel, XLNetTokenizer\n",
        "import re\n",
        "import os\n",
        "import gdown"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7lx7oO5ANX6H",
        "colab_type": "text"
      },
      "source": [
        "<b>2. Set the url location of ProtXLNet and the vocabulary file<b>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zcinbJWSNX6H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "modelUrl = 'https://drive.google.com/uc?export=download&confirm=BTQ_&id=1EbfVSoOGJycJEOKeRD5y5MdobF-wgpew'\n",
        "configUrl = 'https://drive.google.com/uc?export=download&confirm=BTQ_&id=104kJ8GqLIB0XzAqC8s1txV5UtTODWjnH'\n",
        "vocabUrl = 'https://drive.google.com/uc?export=download&confirm=BTQ_&id=1DgkfkHRpDb9rBCmC53rZd5vFk8vZKIaN'"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q_jdpPzWNrYN",
        "colab_type": "text"
      },
      "source": [
        "<b>3. Download ProtXLNet models and vocabulary files<b>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XcYzGYu1Nzi3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "downloadFolderPath = 'models/ProtXLNet/'"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-K50zHErN1sM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "modelFolderPath = downloadFolderPath\n",
        "\n",
        "modelFilePath = os.path.join(modelFolderPath, 'pytorch_model.bin')\n",
        "\n",
        "configFilePath = os.path.join(modelFolderPath, 'config.json')\n",
        "\n",
        "vocabFilePath = os.path.join(modelFolderPath, 'spm_model.model')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oX5HLO3zN1xA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if not os.path.exists(modelFolderPath):\n",
        "    os.makedirs(modelFolderPath)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IU5nfnAWN53R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def download_file(url,filename):\n",
        "  while not os.path.exists(filename):\n",
        "    gdown.download(url,filename, quiet=False)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Lmcr1aRN58c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "a9d88eda-43d7-4ec8-a07a-8e043dfc702b"
      },
      "source": [
        "if not os.path.exists(modelFilePath):\n",
        "    download_file(modelUrl, modelFilePath)\n",
        "\n",
        "if not os.path.exists(configFilePath):\n",
        "    download_file(configUrl, configFilePath)\n",
        "\n",
        "if not os.path.exists(vocabFilePath):\n",
        "    download_file(vocabUrl, vocabFilePath)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?export=download&confirm=BTQ_&id=1EbfVSoOGJycJEOKeRD5y5MdobF-wgpew\n",
            "To: /content/models/ProtXLNet/pytorch_model.bin\n",
            "1.64GB [00:18, 90.9MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?export=download&confirm=BTQ_&id=104kJ8GqLIB0XzAqC8s1txV5UtTODWjnH\n",
            "To: /content/models/ProtXLNet/config.json\n",
            "100%|██████████| 1.35k/1.35k [00:00<00:00, 1.23MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?export=download&confirm=BTQ_&id=1DgkfkHRpDb9rBCmC53rZd5vFk8vZKIaN\n",
            "To: /content/models/ProtXLNet/spm_model.model\n",
            "100%|██████████| 238k/238k [00:00<00:00, 48.6MB/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N8P8PuaPNX6P",
        "colab_type": "text"
      },
      "source": [
        "<b>4. Load the vocabulary and ProtXLNet Model<b>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rCciR4OuNX6Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab = XLNetTokenizer(vocabFilePath, do_lower_case=False)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yq-cm1HvNX6U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xlnet_men_len = 512"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GK96KkaPNX6Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = XLNetModel.from_pretrained(modelFolderPath,mem_len=xlnet_men_len)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4DALWq-uNX6b",
        "colab_type": "text"
      },
      "source": [
        "<b>5. Load the model into the GPU if avilabile and switch to inference mode<b>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJ9x1UkCNX6c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vg-Xq9JINX6e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = model.to(device)\n",
        "model = model.eval()"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LHzvO2rWNX6f",
        "colab_type": "text"
      },
      "source": [
        "<b>6. Create or load sequences and map rarely occured amino acids (U,Z,O,B) to (X)<b>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_yO9KaaCNX6f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sequences_Example = [\"A E T C Z A O\",\"S K T Z P\"]"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4PUKBD7dNX6h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sequences_Example = [re.sub(r\"[UZOB]\", \"X\", sequence) for sequence in sequences_Example]"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xj10emItNX6j",
        "colab_type": "text"
      },
      "source": [
        "<b>7. Tokenize, encode sequences and load it into the GPU if possibile<b>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sr5TAXIsNX6k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ids = vocab.batch_encode_plus(sequences_Example, add_special_tokens=True, pad_to_max_length=True)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "74ktq66hNX6l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_ids = torch.tensor(ids['input_ids']).to(device)\n",
        "attention_mask = torch.tensor(ids['attention_mask']).to(device)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "onNUfYXjNX6t",
        "colab_type": "text"
      },
      "source": [
        "<b>8. Extracting sequences' features and load it into the CPU if needed<b>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "07YVm3IjNX6u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with torch.no_grad():\n",
        "    embedding, memory = model(input_ids=input_ids,attention_mask=attention_mask,mems=None)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VGu2brubNX6x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedding = embedding.cpu().numpy()"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LVRB9g2kNX60",
        "colab_type": "text"
      },
      "source": [
        "<b>9. Remove padding ([PAD]) and special tokens ([CLS],[SEP]) that is added by ProtXLNet model<b>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PSeqr4YdNX60",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "features = [] \n",
        "for seq_num in range(len(embedding)):\n",
        "    seq_len = (attention_mask[seq_num] == 1).sum()\n",
        "    padded_seq_len = len(attention_mask[seq_num])\n",
        "    seq_emd = embedding[seq_num][padded_seq_len-seq_len:padded_seq_len-2]\n",
        "    features.append(seq_emd)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4h3DOjYZNX62",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "09afaf99-417b-4a64-c698-722d8c34f809"
      },
      "source": [
        "print(features)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[array([[ 0.48745194, -0.770879  ,  0.99001765, ..., -0.37356165,\n",
            "        -1.0589758 ,  0.9559981 ],\n",
            "       [ 0.21325967, -0.5478905 ,  0.61154914, ..., -0.0547137 ,\n",
            "        -0.8787893 ,  0.24645106],\n",
            "       [ 0.37891382, -0.63965815,  0.6722441 , ..., -0.14891182,\n",
            "        -0.6769571 ,  0.34598157],\n",
            "       ...,\n",
            "       [ 0.09265058, -0.68101126,  0.5181862 , ..., -0.3275623 ,\n",
            "        -0.5673123 , -0.16441283],\n",
            "       [-0.08533144, -0.7438235 ,  0.29890785, ..., -0.2437637 ,\n",
            "        -0.11153173, -0.7260989 ],\n",
            "       [-0.4822571 , -0.8381702 ,  0.08214345, ..., -0.25196436,\n",
            "        -0.03577353, -0.5348941 ]], dtype=float32), array([[ 1.0403053 , -0.95049226,  0.3353453 , ..., -0.23747277,\n",
            "        -0.27550653,  0.47948802],\n",
            "       [ 0.50853604, -0.9508459 ,  1.0235127 , ..., -0.05893146,\n",
            "        -0.9752788 ,  0.08713217],\n",
            "       [ 0.65626544, -0.7540615 ,  0.43234807, ...,  0.36707586,\n",
            "        -0.7063245 , -0.5553407 ],\n",
            "       [ 0.5903388 ,  0.14151968,  0.29578856, ...,  0.20601138,\n",
            "        -0.8735826 ,  0.80679464],\n",
            "       [ 0.414007  ,  0.61317   ,  0.04792242, ...,  0.18511376,\n",
            "        -0.3409829 , -0.41200036]], dtype=float32)]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}